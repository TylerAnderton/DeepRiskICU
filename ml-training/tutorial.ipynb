{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Overview</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to combine data from a few different tables in the MIMIC-III dataset to train an XGBoost Classifier to predict if a patient is likely to die based only on the data available within 24 hours of their time of admission. Such a classifier can help caregivers triage their patients, allocating vital resources to those with the greatest chance at survival while identifying cases where palliative care is more appropriate.\n",
    "\n",
    "While a final production model could certainly include a much wider variety of features, the data considered for this proof-of-concept are limited to the ADMISSIONS, PATIENTS, NOTEEVENTS, and PRESCRIPTIONS tables of the MIMIC-III dataset.\n",
    "\n",
    "From the ADMISSIONS table, we include the admission location, insurance type, ethnicity, and the ground truth label of an in-hospital death. We also merge the gender and age of the patient from the PATIENTS table to these data.\n",
    "\n",
    "The NOTEEVENTS table includes a wide variety of notes writen by nurses, physicians, radiologists, etc for each hospital admission. We use ClinicalBERT to tokenize and embed these notes before performing PCA on these embeddings and feeding these features into the XGBoost model.\n",
    "\n",
    "Similarly, we take the names of the medications started within 24 hours of admission from the PRESCRIPTIONS table, tokenize, embed, and use PCA to add these data as features for the XGBoost model as well. \n",
    "\n",
    "Finally, we combine all features for each admission and tune an XGBoost model with RandomizedSearchCV to achieve 0.79 PR AUC and 0.85 precision on the true (death) labels. Since life-saving resources may be diverted away from patients whom this model predicts are most likely to die in-hospital, precision on the true class will determine the correctness of specifically these predictions and can be considered the most important metric for this model.\n",
    "\n",
    "Note: Throughout the notebook, you will see many lines commented-out. This is for the purpose of hiding any cell outputs that would otherwise contain sensitive patient data. Please un-comment these lines before running these cells to view the output when connected to your own MIMIC-III data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Setup</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyx-ai/miniconda3/envs/aih311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own path to the MIMIC-III dataset\n",
    "mimic_iii_path = '/mnt/2TB-HDD-Ubuntu/GitHub-Repositories/UT Austin/2025 Spring/AI-Healthcare/MIMIC-III-Dataset/mimic-iii-clinical-database-1.4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Import data</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to filter out rows from NOTEEVENTS and PRESCRIPTIONS that are timestamped after 24 hours of admission\n",
    "def filter_df_24h(admissions_df, data_df, log_dt_col:str) -> pd.DataFrame:\n",
    "    merged_df = pd.merge(\n",
    "        data_df,\n",
    "        admissions_df[['HADM_ID', 'ADMITTIME', 'DEATH']],\n",
    "        on='HADM_ID',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Calculate time difference between CHARTTIME and ADMITTIME\n",
    "    merged_df['time_diff_hours'] = (merged_df[log_dt_col] - merged_df['ADMITTIME']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Filter rows where CHARTTIME is within 24 hours after ADMITTIME\n",
    "    merged_24h_df = merged_df[merged_df['time_diff_hours'] <= 24].copy()\n",
    "\n",
    "    # Drop the temporary column we created\n",
    "    merged_24h_df = merged_24h_df.drop(['time_diff_hours'], axis=1)\n",
    "\n",
    "    return merged_24h_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv(os.path.join(mimic_iii_path, 'ADMISSIONS.csv'))\n",
    "# admissions_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the ADMISSION_TYPE values reveals many NEWBORN and ELECTIVE admissions that are not likely relevant for triage. While we filter down admissions_df to include only the helpful columns, we will also drop any rows that are not EMERGENCY or URGENT types. We will also define our gold label DEATH column as a boolean and ensure that the ADMITTIME and DEATHTIME columns are datetime types.\n",
    "\n",
    "Note that we do not keep the DIAGNOSIS column, although it would be relevant, as there is no way to determine at what time each diagnosis was made, and we therefore could not possibly filter these to the first 24 hours of each admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADMISSION_TYPE\n",
       "EMERGENCY    42071\n",
       "NEWBORN       7863\n",
       "ELECTIVE      7706\n",
       "URGENT        1336\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_df['ADMISSION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_cols = [\n",
    "    'SUBJECT_ID',\n",
    "    'HADM_ID',\n",
    "    'ADMITTIME',\n",
    "    'DEATHTIME',\n",
    "    'ADMISSION_LOCATION',\n",
    "    'INSURANCE',\n",
    "    'ETHNICITY'\n",
    "]\n",
    "\n",
    "emergency_urgent = [\n",
    "    'EMERGENCY',\n",
    "    'URGENT'\n",
    "]\n",
    "\n",
    "admissions_df_filtered = admissions_df[admissions_df['ADMISSION_TYPE'].isin(emergency_urgent)][admissions_cols].reset_index(drop=True)\n",
    "admissions_df_filtered['DEATH'] = ~admissions_df_filtered['DEATHTIME'].isna()\n",
    "\n",
    "admissions_df_filtered['ADMITTIME'] = pd.to_datetime(admissions_df_filtered['ADMITTIME'])\n",
    "admissions_df_filtered['DEATHTIME'] = pd.to_datetime(admissions_df_filtered['DEATHTIME'])\n",
    "\n",
    "# admissions_df_filtered # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31894/3574246920.py:1: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  noteevents_df = pd.read_csv(os.path.join(mimic_iii_path, 'NOTEEVENTS.csv'))\n"
     ]
    }
   ],
   "source": [
    "noteevents_df = pd.read_csv(os.path.join(mimic_iii_path, 'NOTEEVENTS.csv'))\n",
    "# noteevents_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we display a few samples of the notes, and we see a wide variety of formats and information included. This can also be seen by inspecting the CATEGORY values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out for privacy\n",
    "# for note in noteevents_df['TEXT'].sample(10, random_state=42):\n",
    "#     print(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "Nursing/other        822497\n",
       "Radiology            522279\n",
       "Nursing              223556\n",
       "ECG                  209051\n",
       "Physician            141624\n",
       "Discharge summary     59652\n",
       "Echo                  45794\n",
       "Respiratory           31739\n",
       "Nutrition              9418\n",
       "General                8301\n",
       "Rehab Services         5431\n",
       "Social Work            2670\n",
       "Case Management         967\n",
       "Pharmacy                103\n",
       "Consult                  98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noteevents_df['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set the type of the datetime columns and remove all rows where ISERROR is not null while filtering down the columns. We also remove any rows with missing CHARTTIMEs, as these make them impossible to filter by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2083180 entries, 0 to 2083179\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   ROW_ID       int64         \n",
      " 1   SUBJECT_ID   int64         \n",
      " 2   HADM_ID      float64       \n",
      " 3   CHARTDATE    datetime64[ns]\n",
      " 4   CHARTTIME    datetime64[ns]\n",
      " 5   STORETIME    datetime64[ns]\n",
      " 6   CATEGORY     object        \n",
      " 7   DESCRIPTION  object        \n",
      " 8   CGID         float64       \n",
      " 9   ISERROR      float64       \n",
      " 10  TEXT         object        \n",
      "dtypes: datetime64[ns](3), float64(3), int64(2), object(3)\n",
      "memory usage: 174.8+ MB\n"
     ]
    }
   ],
   "source": [
    "noteevents_df['CHARTDATE'] = pd.to_datetime(noteevents_df['CHARTDATE'])\n",
    "noteevents_df['CHARTTIME'] = pd.to_datetime(noteevents_df['CHARTTIME'])\n",
    "noteevents_df['STORETIME'] = pd.to_datetime(noteevents_df['STORETIME'])\n",
    "noteevents_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISERROR\n",
       "1.0    886\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noteevents_df['ISERROR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_cols = [\n",
    "    'SUBJECT_ID',\n",
    "    'HADM_ID',\n",
    "    'CHARTTIME',\n",
    "    'TEXT'\n",
    "]\n",
    "\n",
    "noteevents_df_filtered = noteevents_df[\n",
    "    (noteevents_df['ISERROR'].isna())\\\n",
    "    &\\\n",
    "    (~noteevents_df['CHARTTIME'].isna())\n",
    "][noteevents_cols].copy()\n",
    "# noteevents_df_filtered # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally here we filter out any notes with a CHARTTIME more than 24 hours after the time of admission, and we see an average of 6 notes per admission remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_df_filtered_24h = filter_df_24h(admissions_df_filtered, noteevents_df_filtered, 'CHARTTIME').reset_index(drop=True)\n",
    "# noteevents_df_filtered_24h # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.981649941352796"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noteevents_df_filtered_24h['HADM_ID'].value_counts().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df = pd.read_csv(os.path.join(mimic_iii_path, 'PATIENTS.csv'))\n",
    "# patients_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, we set the datetime DOB (date of birth) column to the proper type and filter down patients_df to just the columns we need. We also convert the string male/female GENDER column into a binary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_cols = [\n",
    "    'SUBJECT_ID',\n",
    "    'GENDER',\n",
    "    'DOB'\n",
    "]\n",
    "\n",
    "patients_df['DOB'] = pd.to_datetime(patients_df['DOB'])\n",
    "\n",
    "patients_df_filtered = patients_df[patients_cols].copy()\n",
    "\n",
    "# Convert gender to binary feature (0 for female, 1 for male)\n",
    "patients_df_filtered['GENDER_BINARY'] = patients_df_filtered['GENDER'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# patients_df_filtered # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31894/3760450926.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  prescriptions_df = pd.read_csv(os.path.join(mimic_iii_path, 'PRESCRIPTIONS.csv'))\n"
     ]
    }
   ],
   "source": [
    "prescriptions_df = pd.read_csv(os.path.join(mimic_iii_path, 'PRESCRIPTIONS.csv'))\n",
    "# prescriptions_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon first inspection, it's easy to see many missing drug names and codes in prescriptions_df. We inspect the null counts for each identifying column and find that only DRUG has no missing values. This will be the drug identifier column we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRUG                       0\n",
       "DRUG_NAME_POE        1664234\n",
       "DRUG_NAME_GENERIC    1662989\n",
       "GSN                   507164\n",
       "NDC                     4463\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prescriptions_df[['DRUG', 'DRUG_NAME_POE', 'DRUG_NAME_GENERIC', 'GSN', 'NDC']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRUG\n",
       "Potassium Chloride      192993\n",
       "Insulin                 143465\n",
       "D5W                     142241\n",
       "Furosemide              133122\n",
       "0.9% Sodium Chloride    130147\n",
       "                         ...  \n",
       "Renaphro                     1\n",
       "Morphine Sulfat              1\n",
       "humulin R                    1\n",
       "Meperidine PCA               1\n",
       "rasagiline (Azilect)         1\n",
       "Name: count, Length: 4525, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prescriptions_df['DRUG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've done many times before, we convert STARTDATE to a datetime, filter the columns down, and then filter out all rows more than 24 hours after the admission datetime, leaving us with an average of 32 prescriptions for each HADM_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_cols = [\n",
    "    'HADM_ID',\n",
    "    'STARTDATE',\n",
    "    'DRUG'\n",
    "]\n",
    "\n",
    "prescriptions_df['STARTDATE'] = pd.to_datetime(prescriptions_df['STARTDATE'])\n",
    "\n",
    "\n",
    "prescriptions_df_filtered = prescriptions_df[prescriptions_cols].copy()\n",
    "# prescriptions_df_filtered # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_df_filtered_24h = filter_df_24h(admissions_df_filtered, prescriptions_df_filtered, 'STARTDATE').reset_index(drop=True)\n",
    "# prescriptions_df_filtered_24h # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.953456674827734"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prescriptions_df_filtered_24h['HADM_ID'].value_counts().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Feature Engineering</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used after aggregating the NOTEEVENTS and PRESCRIPTIONS features by HADM_ID\n",
    "# This is simply to verify the aggregation process was successful\n",
    "def assert_unique_HADM_ID(df):\n",
    "    assert df['HADM_ID'].nunique() == len(df), 'Some HADM_IDs have multiple rows'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions-Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join patients\n",
    "\n",
    "First we join the PATIENTS data to admissions_df_filtered by SUBJECT_ID. This will attach the patients' DOB and gender to each of their ADMISSIONS rows. \n",
    "\n",
    "We then calcuate the age at the time of admission by subtracting their DOB from the admission datetime. This ended up being more complicated than expected, as roughly 2500 admissions were paired with patients' DOBs in the 1800s -- in each case almost exactly 300 years before their admission. Obviously something went wrong with either the data entry or the anonymization transformations applied to the DOB values. These rows were dropped from the resulting table and the remaining ages were inspected to make sure they seemed reasonable with a mean age of 62 and a maximum of 89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_patients_df = pd.merge(\n",
    "    admissions_df_filtered,\n",
    "    patients_df_filtered,\n",
    "    on='SUBJECT_ID',\n",
    "    how='inner'\n",
    ")\n",
    "# admissions_patients_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HADM_ID: 2178-09-17 18:31:00 - 1878-09-17 00:00:00 has unreasonable age difference: 300\n"
     ]
    }
   ],
   "source": [
    "from pandas._libs.tslibs.np_datetime import OutOfBoundsDatetime\n",
    "\n",
    "# I'll save a single error message as an example, so you don't have to read thousands of lines of output\n",
    "example_error = None\n",
    "\n",
    "# Calculate age safely with error handling for extreme date ranges\n",
    "def calculate_age(admit_date, birth_date):\n",
    "    global example_error\n",
    "    try:\n",
    "        return (admit_date - birth_date).days / 365\n",
    "    except (OverflowError, OutOfBoundsDatetime):\n",
    "        # If dates are too extreme, check if year difference is reasonable\n",
    "        year_diff = admit_date.year - birth_date.year\n",
    "        if 0 <= year_diff <= 120:  # Reasonable age range\n",
    "            return year_diff\n",
    "        else:\n",
    "            # print(f'HADM_ID: {admit_date} - {birth_date} has unreasonable age difference: {year_diff}')\n",
    "            example_error = f'HADM_ID: {admit_date} - {birth_date} has unreasonable age difference: {year_diff}'\n",
    "            return float('nan')  # Return NaN for unreasonable values\n",
    "\n",
    "# Apply the safer calculation\n",
    "admissions_patients_df['AGE_YRS'] = admissions_patients_df.apply(\n",
    "    lambda row: calculate_age(row['ADMITTIME'], row['DOB']), axis=1\n",
    ")\n",
    "\n",
    "print(example_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2507"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_patients_df['AGE_YRS'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40900.000000\n",
       "mean        61.983834\n",
       "std         17.691616\n",
       "min          0.000000\n",
       "25%         51.035616\n",
       "50%         64.230137\n",
       "75%         76.394521\n",
       "max         89.060274\n",
       "Name: AGE_YRS, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_patients_df.dropna(subset=['AGE_YRS'], inplace=True, ignore_index=True)\n",
    "admissions_patients_df['AGE_YRS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each column in the merged DataFrame that we plan to use as features, we print out the number of unique values. 5 INSURANCE values or 9 ADMISSION_LOCATION values are manageable for categorical features, but 41 distinct ETHNICITY values definitely seems excessive. \n",
    "\n",
    "Upon further inspection, we see that the ETHNICITY field was never standardized, as there are many overlapping ethnicities and multiple ethinicities combined into many values. There are also various 'OTHER' or 'DECLINED TO ANSWER' values that provide no information at all.\n",
    "\n",
    "There are probably better ways to do this, but for now we just define five ethnicity 'buckets' to categorize these values into. We assign these ethnicity buckets simply by if they appear in the ETHNICITY value, in order of commonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT_ID unique values: 31663\n",
      "HADM_ID unique values: 40900\n",
      "ADMISSION_LOCATION unique values: 9\n",
      "INSURANCE unique values: 5\n",
      "ETHNICITY unique values: 41\n",
      "GENDER_BINARY unique values: 2\n",
      "AGE_YRS unique values: 18887\n"
     ]
    }
   ],
   "source": [
    "admissions_patients_feature_cols = [\n",
    "    # Admissions features\n",
    "    'SUBJECT_ID',\n",
    "    'HADM_ID',\n",
    "    'ADMISSION_LOCATION',\n",
    "    'INSURANCE',\n",
    "    'ETHNICITY',\n",
    "    # Patients features\n",
    "    'GENDER_BINARY',\n",
    "    'AGE_YRS'\n",
    "]\n",
    "for column in admissions_patients_feature_cols:\n",
    "    print(f'{column} unique values: {admissions_patients_df[column].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETHNICITY\n",
       "WHITE                                                       0.698044\n",
       "BLACK/AFRICAN AMERICAN                                      0.097450\n",
       "UNKNOWN/NOT SPECIFIED                                       0.081876\n",
       "HISPANIC OR LATINO                                          0.026977\n",
       "OTHER                                                       0.022231\n",
       "UNABLE TO OBTAIN                                            0.016173\n",
       "ASIAN                                                       0.016034\n",
       "PATIENT DECLINED TO ANSWER                                  0.006819\n",
       "HISPANIC/LATINO - PUERTO RICAN                              0.004700\n",
       "ASIAN - CHINESE                                             0.004354\n",
       "BLACK/CAPE VERDEAN                                          0.003410\n",
       "WHITE - RUSSIAN                                             0.003340\n",
       "BLACK/HAITIAN                                               0.002143\n",
       "MULTI RACE ETHNICITY                                        0.002050\n",
       "HISPANIC/LATINO - DOMINICAN                                 0.001520\n",
       "ASIAN - ASIAN INDIAN                                        0.001520\n",
       "PORTUGUESE                                                  0.001152\n",
       "WHITE - OTHER EUROPEAN                                      0.001083\n",
       "WHITE - BRAZILIAN                                           0.001060\n",
       "ASIAN - VIETNAMESE                                          0.000875\n",
       "BLACK/AFRICAN                                               0.000852\n",
       "HISPANIC/LATINO - GUATEMALAN                                0.000806\n",
       "MIDDLE EASTERN                                              0.000806\n",
       "AMERICAN INDIAN/ALASKA NATIVE                               0.000507\n",
       "ASIAN - FILIPINO                                            0.000507\n",
       "HISPANIC/LATINO - CUBAN                                     0.000438\n",
       "WHITE - EASTERN EUROPEAN                                    0.000392\n",
       "ASIAN - CAMBODIAN                                           0.000392\n",
       "HISPANIC/LATINO - SALVADORAN                                0.000369\n",
       "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER                   0.000299\n",
       "ASIAN - OTHER                                               0.000253\n",
       "ASIAN - KOREAN                                              0.000253\n",
       "HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)                  0.000253\n",
       "HISPANIC/LATINO - MEXICAN                                   0.000230\n",
       "SOUTH AMERICAN                                              0.000161\n",
       "HISPANIC/LATINO - COLOMBIAN                                 0.000161\n",
       "CARIBBEAN ISLAND                                            0.000161\n",
       "ASIAN - JAPANESE                                            0.000115\n",
       "HISPANIC/LATINO - HONDURAN                                  0.000092\n",
       "ASIAN - THAI                                                0.000069\n",
       "AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE    0.000069\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions_df_filtered['ETHNICITY'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_buckets = [\n",
    "    'WHITE',\n",
    "    'BLACK',\n",
    "    'HISPANIC',\n",
    "    'ASIAN'\n",
    "]\n",
    "\n",
    "def map_ethnicity(ethnicity_str):\n",
    "    ethnicity_upper = ethnicity_str.upper()\n",
    "    for bucket in ethnicity_buckets:\n",
    "        if bucket in ethnicity_upper:\n",
    "            return bucket\n",
    "    return 'OTHER'\n",
    "\n",
    "\n",
    "admissions_patients_df['ETHNICITY_BUCKET'] = admissions_patients_df['ETHNICITY'].apply(map_ethnicity)\n",
    "admissions_patients_df['ETHNICITY_BUCKET'].value_counts(normalize=True)\n",
    "\n",
    "admissions_patients_feature_cols.append('ETHNICITY_BUCKET')\n",
    "admissions_patients_feature_cols.remove('ETHNICITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally for these data, we convert all features except AGE_YRS into categorical type columns that can be parsed by XGBoost without much more work, add the DEATH label back onto the DataFrame, and assert that each HADM_ID has its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_patients_features_df = admissions_patients_df[admissions_patients_feature_cols].copy()\n",
    "\n",
    "for col in admissions_patients_feature_cols:\n",
    "    if col != 'AGE_YRS':  # Only convert non-numeric columns to category\n",
    "        admissions_patients_features_df[col] = admissions_patients_features_df[col].astype('category')\n",
    "\n",
    "admissions_patients_features_df['DEATH'] = admissions_patients_df['DEATH']\n",
    "# admissions_patients_features_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40900 entries, 0 to 40899\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   SUBJECT_ID          40900 non-null  category\n",
      " 1   HADM_ID             40900 non-null  category\n",
      " 2   ADMISSION_LOCATION  40900 non-null  category\n",
      " 3   INSURANCE           40900 non-null  category\n",
      " 4   GENDER_BINARY       40900 non-null  category\n",
      " 5   AGE_YRS             40900 non-null  float64 \n",
      " 6   ETHNICITY_BUCKET    40900 non-null  category\n",
      " 7   DEATH               40900 non-null  bool    \n",
      "dtypes: bool(1), category(6), float64(1)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "admissions_patients_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_unique_HADM_ID(admissions_patients_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the clinicalBERT model from HuggingFace and write a function that will return the embeddings for a batch of input strings. \n",
    "\n",
    "Note here that the `tokenizer_max_length` is set to 512 as that is the maximum input size for clinicalBERT. We also use `truncation=True` in the tokenizer to ensure that no token sequences will exceed this length, but unfortunately this does mean that many (almost half) of our notes are getting truncated to some extent. This can be seen by tokenizing a random sample of 1000 notes and inspecting their statistics, showing a median token sequence length 459.\n",
    "\n",
    "Also note that each embedding output from clinicalBERT will be of shape (768,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinicalBERT = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "clinicalBERT_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "def get_bert_embeddings(texts:list[str], model, tokenizer, batch_size=32, tokenizer_max_length=512) -> np.ndarray:\n",
    "    if torch.cuda.is_available():\n",
    "        print('Using CUDA')\n",
    "        model = model.cuda()\n",
    "\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_idx = i // batch_size\n",
    "        if batch_idx % 20 == 0: # Print every 50 batches\n",
    "            print(f'Processing batch {batch_idx} of {len(texts) // batch_size}')\n",
    "            \n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=\"max_length\", truncation=True, \n",
    "                          max_length=tokenizer_max_length, return_tensors=\"pt\")  # Reduced max_length\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Processing batch 0 of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = \"Patient presented with hypotension and low oxygen saturation.\"\n",
    "embedding = get_bert_embeddings([example_text], clinicalBERT, clinicalBERT_tokenizer, batch_size=1)\n",
    "embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_test_tokens = noteevents_df_filtered_24h['TEXT'].sample(1000, random_state=42)\\\n",
    "    .apply(lambda x: clinicalBERT_tokenizer.encode(x, truncation=False))\n",
    "# noteevents_test_tokens # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum token length: 13\n",
      "Maximum token length: 5069\n",
      "Mean token length: 673.372\n",
      "Median token length: 459.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Minimum token length: {noteevents_test_tokens.apply(len).min()}')\n",
    "print(f'Maximum token length: {noteevents_test_tokens.apply(len).max()}')\n",
    "print(f'Mean token length: {noteevents_test_tokens.apply(len).mean()}')\n",
    "print(f'Median token length: {noteevents_test_tokens.apply(len).median()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following cell to generate the embeddings for all notes in our dataset, but note here that this took 24 minutes to process 229486 notes on a RTX 4070 Super GPU. To avoid re-calculating these embeddings, I've also included code here to save and load them as a numpy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noteevents_embeddings = get_bert_embeddings_batched( # uncomment to run\n",
    "#     list(noteevents_df_filtered_24h['TEXT']),\n",
    "#     clinicalBERT,\n",
    "#     clinicalBERT_tokenizer,\n",
    "#     batch_size=256 # Takes about 10GB of GPU memory\n",
    "# )\n",
    "# noteevents_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_embeddings_path = os.path.join('feature-embeddings', 'noteevents_embeddings.npy')\n",
    "\n",
    "# np.save(noteevents_embeddings_path, noteevents_embeddings)\n",
    "# print(f\"Saved embeddings to {noteevents_embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229486, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noteevents_embeddings = np.load(noteevents_embeddings_path)\n",
    "noteevents_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have embeddings for each note, we still have about 6 notes per hospital admission. We need to aggregate these embeddings by taking the average and count for each HADM_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_embeddings_df = pd.DataFrame({\n",
    "    'HADM_ID': noteevents_df_filtered_24h['HADM_ID'],\n",
    "    'NOTE_EMBEDDING': list(noteevents_embeddings),\n",
    "    'DEATH': noteevents_df_filtered_24h['DEATH']\n",
    "})\n",
    "# noteevents_embeddings_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_embeddings_df_avg = noteevents_embeddings_df.groupby('HADM_ID').agg(\n",
    "    NOTE_EMBEDDING_AVG=('NOTE_EMBEDDING', lambda x: np.mean(np.vstack(x), axis=0)),\n",
    "    NOTE_COUNT=('NOTE_EMBEDDING', 'count'),  # Count number of notes per HADM_ID\n",
    "    DEATH=('DEATH', 'first')  # Keep the first DEATH value (all are the same per HADM_ID)\n",
    ").reset_index()\n",
    "# noteevents_embeddings_df_avg # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remember that each embedding is of shape (768,), which is far too large to reasonably put into an XGBoost as raw features. To make the dimension more manageable, we'll perform PCA on each HADM_ID's average note embedding and take the top 10 components to retain 86% of the embeddings' variance. These 10 components and the NOTE_COUNT will make up the final features from our NOTEEVENTS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by PCA components: 0.8556\n"
     ]
    }
   ],
   "source": [
    "# Stack the embeddings into a numpy array\n",
    "noteevents_embeddings_array = np.vstack(noteevents_embeddings_df_avg['NOTE_EMBEDDING_AVG'].values)\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=10) # 10 components retain 86% variance\n",
    "noteevents_reduced_embeddings = pca.fit_transform(noteevents_embeddings_array)\n",
    "\n",
    "# Create DataFrame with reduced embeddings\n",
    "noteevents_features_df = pd.DataFrame(\n",
    "    noteevents_reduced_embeddings, \n",
    "    columns=[f'note_pca_{i}' for i in range(noteevents_reduced_embeddings.shape[1])]\n",
    ")\n",
    "\n",
    "# Add back HADM_ID, NOTE_COUNT, 7 DEATH columns\n",
    "noteevents_features_df['HADM_ID'] = noteevents_embeddings_df_avg['HADM_ID'].astype('category')\n",
    "noteevents_features_df['NOTE_COUNT'] = noteevents_embeddings_df_avg['NOTE_COUNT']\n",
    "noteevents_features_df['DEATH'] = noteevents_embeddings_df_avg['DEATH']\n",
    "\n",
    "print(f\"Variance explained by PCA components: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "# noteevents_features_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_unique_HADM_ID(noteevents_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prescriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did to get the embedding features for NOTEEVENTS, we do almost the same to get the features for the DRUG names in PRESCRIPTIONS. The only noteable difference is that the embeddings for the DRUG names are much shorter than the notes, allowing us to drop the `tokenizer_max_length` down to 32 and make the embedding processing much more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_feature_cols = [\n",
    "    'HADM_ID',\n",
    "    'DRUG'\n",
    "]\n",
    "prescriptions_features_df_many = prescriptions_df_filtered_24h[prescriptions_feature_cols].copy()\n",
    "\n",
    "prescriptions_features_df_many['DEATH'] = prescriptions_df_filtered_24h['DEATH']\n",
    "# prescriptions_features_df_many # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ClinicalBERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_test_tokens = prescriptions_features_df_many['DRUG'].sample(1000, random_state=42)\\\n",
    "    .apply(lambda x: clinicalBERT_tokenizer.encode(x, truncation=False))\n",
    "# prescriptions_test_tokens # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum token length: 3\n",
      "Maximum token length: 22\n",
      "Mean token length: 7.182\n",
      "Median token length: 7.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Minimum token length: {prescriptions_test_tokens.apply(len).min()}')\n",
    "print(f'Maximum token length: {prescriptions_test_tokens.apply(len).max()}')\n",
    "print(f'Mean token length: {prescriptions_test_tokens.apply(len).mean()}')\n",
    "print(f'Median token length: {prescriptions_test_tokens.apply(len).median()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prescriptions_embeddings = get_bert_embeddings_batched( # uncomment to run\n",
    "#     list(prescriptions_features_df_many['DRUG']),\n",
    "#     clinicalBERT,\n",
    "#     clinicalBERT_tokenizer,\n",
    "#     tokenizer_max_length=32, # Reduce max_length to 32 to match max token length of 22\n",
    "#     batch_size=256 # Takes about 10GB of GPU memory\n",
    "# )\n",
    "# prescriptions_embeddings # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_embeddings_path = os.path.join(os.getcwd(), 'feature-embeddings', 'prescriptions_embeddings.npy')\n",
    "\n",
    "# np.save(prescriptions_embeddings_path, prescriptions_embeddings)\n",
    "# print(f\"Saved embeddings to {prescriptions_embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265964, 768)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prescriptions_embeddings = np.load(prescriptions_embeddings_path)\n",
    "prescriptions_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_embeddings_df = pd.DataFrame({\n",
    "    'HADM_ID': prescriptions_features_df_many['HADM_ID'],\n",
    "    'DRUG_EMBEDDING': list(prescriptions_embeddings),\n",
    "    'DEATH': prescriptions_features_df_many['DEATH']\n",
    "})\n",
    "# prescriptions_embeddings_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After embedding each DRUG name, again we aggregate by averaging the embeddings for each HADM_ID and apply PCA to these embedding averages, keeping the top 10 components for 72% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescriptions_embeddings_df_avg = prescriptions_embeddings_df.groupby('HADM_ID').agg(\n",
    "    DRUG_EMBEDDING_AVG=('DRUG_EMBEDDING', lambda x: np.mean(np.vstack(x), axis=0)),\n",
    "    DRUG_COUNT=('DRUG_EMBEDDING', 'count'),  # Count number of drugs per HADM_ID\n",
    "    DEATH=('DEATH', 'first')  # Keep the first DEATH value (all are the same per HADM_ID)\n",
    ").reset_index()\n",
    "\n",
    "# prescriptions_embeddings_df_avg # commented out for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by PCA components: 0.7163\n"
     ]
    }
   ],
   "source": [
    "# Stack the embeddings into a numpy array\n",
    "prescriptions_embeddings_array = np.vstack(prescriptions_embeddings_df_avg['DRUG_EMBEDDING_AVG'].values)\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=10) # 10 components retain 72% variance\n",
    "prescriptions_reduced_embeddings = pca.fit_transform(prescriptions_embeddings_array)\n",
    "\n",
    "# Create DataFrame with reduced embeddings\n",
    "prescriptions_features_df = pd.DataFrame(\n",
    "    prescriptions_reduced_embeddings, \n",
    "    columns=[f'rx_pca_{i}' for i in range(prescriptions_reduced_embeddings.shape[1])]\n",
    ")\n",
    "\n",
    "# Add back HADM_ID, DRUG_COUNT, & DEATH columns\n",
    "prescriptions_features_df['HADM_ID'] = prescriptions_embeddings_df_avg['HADM_ID'].astype('category')\n",
    "prescriptions_features_df['DRUG_COUNT'] = prescriptions_embeddings_df_avg['DRUG_COUNT']\n",
    "prescriptions_features_df['DEATH'] = prescriptions_embeddings_df_avg['DEATH']\n",
    "\n",
    "print(f\"Variance explained by PCA components: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "# prescriptions_features_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_unique_HADM_ID(prescriptions_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Tune Final XGBoost Classifier</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done. Now we just need to merge our feature sets together by HADM_ID before plugging into an XGBoost model and tuning to get the highest precision possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the features in two steps, first joining the noteevents features to the admissions, then joining the prescription features to this merged feature set. We then do a final assertion to ensure that HADM_ID is unique to each row and a last check on our column datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features_df = pd.merge(\n",
    "    admissions_patients_features_df,\n",
    "    noteevents_features_df,\n",
    "    on=['HADM_ID', 'DEATH'],\n",
    "    how='inner'\n",
    ")\n",
    "# merged_features_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features_df = pd.merge(\n",
    "    merged_features_df,\n",
    "    prescriptions_features_df,\n",
    "    on=['HADM_ID', 'DEATH'],\n",
    "    how='inner'\n",
    ")\n",
    "# merged_features_df # commented out for privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_unique_HADM_ID(merged_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_features_df['HADM_ID'] = merged_features_df['HADM_ID'].astype('category')\n",
    "merged_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune and eval XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the very last step we write a script that first tunes the hyperparameters of an `XGBClassifier` using `RandomizedSearchCV` to iterate over 5 folds 30 times each, then takes the best model parameters and evaluates its performance on a 80/20 train-test split of our entire dataset. \n",
    "\n",
    "There are some details to pay attention to here. Firstly, notice that our dataset has a massive class imbalance, with only 11.9% True labels. We address this by setting the `scale_pos_weight` of the XGBoost Classifier accordingly. We also make sure to pay attention to weighted performance metrics when possible. \n",
    "\n",
    "Second is that many of our features are of categorical type. If we were training another model, like logistic regression, we would have to encode these values somehow, but luckily `XGBClassifier` supports categorical variables natively as long as we set `enable_categorical = True`. \n",
    "\n",
    "Third, we set `RandomizedSearchCV` to optimize for precision, since specifically precision on the true labels is the most important metric for this model. \n",
    "\n",
    "Fourth and finally, we display the feature importances for the best model for the purpose of interpretability. While we can't dive into the black box of the embedding PCA components, we can see that the top components for the notes and the prescriptions were two of the most impactful features in predicting their in-hospital death, along with the patient's age and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880769926989682"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_deathrate = merged_features_df['DEATH'].mean()\n",
    "merged_deathrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "====================\n",
      "Best Precision Score: 0.5272\n",
      "Best Parameters:\n",
      "colsample_bytree: 0.7727780074568463\n",
      "gamma: 0.14561457009902096\n",
      "learning_rate: 0.1323705789444759\n",
      "max_depth: 4\n",
      "min_child_weight: 3\n",
      "n_estimators: 463\n",
      "reg_alpha: 0.5142344384136116\n",
      "reg_lambda: 6.924145688620425\n",
      "scale_pos_weight: 1.4645041271999772\n",
      "subsample: 0.8430179407605753\n",
      "\n",
      "Best Model Metrics:\n",
      "Accuracy: 0.9291101055806938\n",
      "ROC AUC: 0.9575\n",
      "PR AUC: 0.7909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.96      5834\n",
      "        True       0.85      0.50      0.63       796\n",
      "\n",
      "    accuracy                           0.93      6630\n",
      "   macro avg       0.89      0.74      0.79      6630\n",
      "weighted avg       0.92      0.93      0.92      6630\n",
      "\n",
      "Feature importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>note_pca_3</td>\n",
       "      <td>0.102528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE_YRS</td>\n",
       "      <td>0.072410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rx_pca_2</td>\n",
       "      <td>0.056205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETHNICITY_BUCKET</td>\n",
       "      <td>0.047397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rx_pca_1</td>\n",
       "      <td>0.044369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rx_pca_4</td>\n",
       "      <td>0.042947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>note_pca_7</td>\n",
       "      <td>0.041543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INSURANCE</td>\n",
       "      <td>0.039738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>note_pca_0</td>\n",
       "      <td>0.035433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>note_pca_6</td>\n",
       "      <td>0.035010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DRUG_COUNT</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADMISSION_LOCATION</td>\n",
       "      <td>0.034692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rx_pca_8</td>\n",
       "      <td>0.032717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rx_pca_0</td>\n",
       "      <td>0.031593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rx_pca_9</td>\n",
       "      <td>0.028766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NOTE_COUNT</td>\n",
       "      <td>0.028747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>note_pca_8</td>\n",
       "      <td>0.028337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>note_pca_9</td>\n",
       "      <td>0.027812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rx_pca_3</td>\n",
       "      <td>0.027686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rx_pca_5</td>\n",
       "      <td>0.027676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>note_pca_5</td>\n",
       "      <td>0.027263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>note_pca_2</td>\n",
       "      <td>0.026992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rx_pca_6</td>\n",
       "      <td>0.026452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rx_pca_7</td>\n",
       "      <td>0.026034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>note_pca_1</td>\n",
       "      <td>0.025810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>note_pca_4</td>\n",
       "      <td>0.024637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENDER_BINARY</td>\n",
       "      <td>0.022406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "8           note_pca_3    0.102528\n",
       "3              AGE_YRS    0.072410\n",
       "18            rx_pca_2    0.056205\n",
       "4     ETHNICITY_BUCKET    0.047397\n",
       "17            rx_pca_1    0.044369\n",
       "20            rx_pca_4    0.042947\n",
       "12          note_pca_7    0.041543\n",
       "1            INSURANCE    0.039738\n",
       "5           note_pca_0    0.035433\n",
       "11          note_pca_6    0.035010\n",
       "26          DRUG_COUNT    0.034800\n",
       "0   ADMISSION_LOCATION    0.034692\n",
       "24            rx_pca_8    0.032717\n",
       "16            rx_pca_0    0.031593\n",
       "25            rx_pca_9    0.028766\n",
       "15          NOTE_COUNT    0.028747\n",
       "13          note_pca_8    0.028337\n",
       "14          note_pca_9    0.027812\n",
       "19            rx_pca_3    0.027686\n",
       "21            rx_pca_5    0.027676\n",
       "10          note_pca_5    0.027263\n",
       "7           note_pca_2    0.026992\n",
       "22            rx_pca_6    0.026452\n",
       "23            rx_pca_7    0.026034\n",
       "6           note_pca_1    0.025810\n",
       "9           note_pca_4    0.024637\n",
       "2        GENDER_BINARY    0.022406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare feature and target columns\n",
    "feature_cols = [col for col in merged_features_df.columns if col not in ['HADM_ID', 'SUBJECT_ID', 'DEATH']]\n",
    "X = merged_features_df[feature_cols]\n",
    "y = merged_features_df['DEATH']\n",
    "\n",
    "# Define the hyperparameter search space for randomized search\n",
    "param_dist = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'scale_pos_weight': uniform(1, 10),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(1, 10)\n",
    "}\n",
    "\n",
    "# Create XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='aucpr',\n",
    "    random_state=42,\n",
    "    enable_categorical = True,\n",
    "    scale_pos_weight = 1 / merged_deathrate  # Adjust class imbalance\n",
    ")\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Set up scoring metrics\n",
    "scoring = {\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV with precision as the primary optimization metric\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # Number of parameter settings sampled\n",
    "    scoring=scoring,\n",
    "    refit='precision',  # Optimize for precision\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and results\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"\\n====================\")\n",
    "print(f\"Best Precision Score: {best_score:.4f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Get all the cross-validation results for the best model\n",
    "cv_results = random_search.cv_results_\n",
    "best_index = random_search.best_index_\n",
    "\n",
    "# Train final model with best parameters\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "final_model = XGBClassifier(\n",
    "    **best_params,\n",
    "    objective='binary:logistic',\n",
    "    random_state=42,\n",
    "    enable_categorical = True,\n",
    "    tree_method = 'hist'  # Required for categorical feature support\n",
    ")\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(\"\\nBest Model Metrics:\")\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, final_model.predict_proba(X_test)[:,1]):.4f}\")\n",
    "print(f\"PR AUC: {average_precision_score(y_test, final_model.predict_proba(X_test)[:,1], average='weighted'):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print feature importances\n",
    "importances = final_model.feature_importances_\n",
    "feat_importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print('Feature importances:')\n",
    "display(feat_importances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aih311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
